#!/usr/bin/env python3
"""
Script de prueba funcional para el scraper de P√°gina 12.
Demuestra el flujo completo de scraping y persistencia.
"""
import os
import sys
import django
import asyncio
import logging

# Configurar path para imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configurar Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'src.infrastructure.config.django_settings')
django.setup()

from src.infrastructure.adapters.scrapers.pagina12_scraper import Pagina12Scraper
from src.infrastructure.persistence.django_repositories import DjangoNewsArticleRepository
from src.application.use_cases.scrape_and_persist_articles import ScrapeAndPersistArticlesUseCase
from src.infrastructure.persistence.django_app.models import NewsArticleModel

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def main():
    """Funci√≥n principal del script"""
    print("\n" + "="*70)
    print("TEST FUNCIONAL: Scraper de P√°gina 12")
    print("="*70 + "\n")
    
    # Contar art√≠culos antes
    count_before = NewsArticleModel.objects.filter(fuente="P√°gina 12").count()
    print(f"üìä Art√≠culos de P√°gina 12 en BD antes: {count_before}\n")
    
    # Inicializar componentes
    print("üîß Inicializando componentes...")
    scraper = Pagina12Scraper(max_articles=15)
    repository = DjangoNewsArticleRepository()
    use_case = ScrapeAndPersistArticlesUseCase(scraper, repository)
    print("‚úÖ Componentes inicializados\n")
    
    # Ejecutar scraping
    print("üï∑Ô∏è  Ejecutando scraping de P√°gina 12...")
    print("-" * 70)
    
    try:
        result = await use_case.execute()
        
        print("\n" + "="*70)
        print("RESULTADOS DEL SCRAPING")
        print("="*70)
        print(f"‚úÖ Total scrapeado:     {result['total_scraped']} art√≠culos")
        print(f"‚úÖ Nuevos insertados:   {result['total_new']} art√≠culos")
        print(f"‚ö†Ô∏è  Duplicados:         {result['total_duplicates']} art√≠culos")
        print("="*70 + "\n")
        
        # Contar art√≠culos despu√©s
        count_after = NewsArticleModel.objects.filter(fuente="P√°gina 12").count()
        print(f"üìä Art√≠culos de P√°gina 12 en BD despu√©s: {count_after}")
        print(f"üìà Incremento: +{count_after - count_before} art√≠culos\n")
        
        # Verificar criterio de aceptaci√≥n
        if result['total_new'] > 0 or count_after >= 10:
            print("‚úÖ CRITERIO CUMPLIDO: Al menos 10 art√≠culos de P√°gina 12 en la base de datos")
        else:
            print("‚ö†Ô∏è  ATENCI√ìN: Se necesitan m√°s art√≠culos para cumplir el criterio")
        
        # Mostrar ejemplos de art√≠culos
        print("\n" + "="*70)
        print("EJEMPLOS DE ART√çCULOS EXTRA√çDOS")
        print("="*70)
        
        articles = NewsArticleModel.objects.filter(fuente="P√°gina 12").order_by('-fecha_publicacion')[:5]
        for i, article in enumerate(articles, 1):
            print(f"\n{i}. {article.titulo[:70]}...")
            print(f"   URL: {article.url}")
            print(f"   Fecha: {article.fecha_publicacion.strftime('%Y-%m-%d %H:%M')}")
            print(f"   Contenido: {len(article.contenido)} caracteres")
        
        print("\n" + "="*70)
        print("TEST COMPLETADO EXITOSAMENTE")
        print("="*70 + "\n")
        
    except Exception as e:
        print("\n" + "="*70)
        print("‚ùå ERROR EN EL SCRAPING")
        print("="*70)
        print(f"Error: {e}")
        logger.exception("Error detallado:")
        print("\n" + "="*70 + "\n")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
